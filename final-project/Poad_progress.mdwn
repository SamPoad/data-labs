### Overall plan
read in and review the image data - exploratory

read in the parasitized images
convert to an array
flatten the array, convert the RGB values to grayscale
normalize/scale the data between 0 and 1 (is that what grayscale will be doing?)
keras.normalize between 0 and 1
throw this into a dataframe
label as parasitized
save that to a database table (optional bonus)

read in the normal images
convert to an array
flatten the array, convert the RGB values to grayscale
normalize/scale the data between 0 and 1 (is that what grayscale will be doing?)
keras.normalize between 0 and 1
label as non-parasitized
save that to a database table (optional bonus)

read in the two tables (optional bonus)
concat/join/merge the dataframes
confirm the ~50% split between Classes

train_test_split the data

initialize a Sequential Model

add input layers

compile

determine accuracy

tweak the hyperparameters, determine accuracy at each step

save the final model (pickle it)

grab a few images and run .predict, using .imshow() and .imsave() to grab the images for presentation

create a python file to import the model as a demo


### Improvements / Optionals
have the data store as a SQLite database, and then read from that. 
use multiple python files and a pickled model to show machine learning pipeline knowledge
is a streamlit app or Python GUI relevant? 



### Progress Log

Project began on Feb 25, 2020

Decided to use a Malaria Dataset
<br> taken from https://lhncbc.nlm.nih.gov/publication/pub9932

the plan is to use this dataset to build a predictive model on whether a new entry has malaria or not.

Domain knowledge a bit to go into the staining process to identify malaria in cells, and then how to address visually.

Interesting thing to note about the data
* The CSV file for the uninfected class contains 201 entries since the normal cells from the infected patientsâ€™ slides also make it to the normal cell category (151+50 = 201)

Remember that this will all be a Python file eventually, so pickle the model that you settle on. 

plan - start a Jupyter notebook for relevant sections

Day 1 target - read the images as arrays, take this data and store as a SQL database.
(this will show Python knowledge)
one table as infected, another table as uninfected

Read in the SQL data to start the model (show SQL knowledge)
concat the dataframes and create a target column to identify Malaria (1) or not (0)

the Features of the dataset will be the array information itself.

Review the image processing / neural network lesson - do i need to reduce the complexity of the images at all? 
My images are very small, and few colors, but I have 27.5k of them to process.

Get an overall sense of SIZE of the data. roughly 28,000 images at what pixel height/width? 

Day 1 - ran into - how to get these images into their array of pixel values? 
research: 
https://machinelearningmastery.com/how-to-load-and-manipulate-images-for-deep-learning-in-python-with-pil-pillow/

combined this with existing knowledge of matplotlib.pyplot and matplotlib.Image

first obstacle - how to read in images as an array of pixel data? - solved
second obstacle - how to create a dataframe out of this? because this dataframe will need to be written to a database. while working on this, ran into...
third obstacle - the images are not all the same dimensions, so I'll need to fill in those with null values (can my model handle
null values? maybe continue with the [0, 0, 0,] for black that the images already use?)
    so for both of the image_quantization and the neural_network exercises, we read in those arrays and flatten/ravel them 
    so that the end result of the array is a string of rgbrgbrgb
    similar to the neural network array used.
    (spoke with instructor during this portion, recommended to treat the SQL save and load as a bonus)
    worked a bit more on trying to read/append the arrays into a dataframe, decided to treat the collection as an array, and work 
    out the train_test split of "features" and "target" using array math instead?

Day 2 target - read the SQL together, and concat the dataframes to create the dataset I need to be using. 
Next - work some heavy Principal Component Analysis (PCA) from Module-2 for reducing dimensionality of the images? 
or reduce it to black and white based on whether the stain appears or not?
Day 2 Actual - read in all the images and save to a SQL database
images come in like 
array([[[0., 0., 0.], this is image1, row1, pixel1
        [0., 0., 0.], this is image1, row1, pixel2
        [0., 0., 0.], this is image1, row1, pixel3
        ...,
so i've read each of the parasitized image arrays into a dataframe. remember to git commit this.
but I need to instead build the dataframe so that it has columns for each pixel? so the 3 values for the pixel would be 
a list of 3 numbers within that one cell?
end of day 2 - learned more about my image data, steps to process


Day 3 - have to finish getting the dataframe completed, or figure out how to train-test-split the arrays appropriately
plan is still to follow the neural network path (and later work to tweak the hyper-parameters)
Ideas on the train-test split. read in the entire parasitized data, split the array after?
(this might be a good thing for the SQL database to read in the data in random order like we did for subreddit recommender project)
13,780 parasitized images, take 15% away as test data. (remaining 11,713 parasitized images)
x uninfected images, take 15% away as test data (remaining x uninfected images)

question - since the images are different sizes, the image arrays will be different sizes as well. is this going to present
a problem for the neural network? can it handle that?

next step - begin building the neural network. read up on tensorflow, keras, and the Sequential model
this project will use DeepLearning to identify if malaria is present in a given cell image
built the basic structure of the neural network out. now to run, play with hyperparameters and optional arguments to improve
obstacle - my values for train_X, test_X, train_y, test_y were lists, not arrays like the model wants.
obstacle: my train_X data is a list of image arrays, not a sequence of values like I thought.
    potential solution - when reading in the image arrays, use np.concatenate instead of appending
                need to git commit what i've got so far and then attempt to change. can always roll back if needed.
planned solution: read in the first image in the directory as an array, and concatenate everything into it after that
    will have to rework the train-test-split following this, but the data will be an array instead of a list, ready for the model. 
    answer this question first - what about converting my list of arrays into an array of arrays? 

Day 4 - images are not all the same size, reviewed with instructor options
for example, find the maximum width image, when reading in images, fill up to that point with zeros. 
find the maximum height, when reading in images, fill rows up that height with zeros.
current work-around is to use numpy reshape, with potential future improvement to fill in more black background on the other images
got the data reading in in the format I want to use!!!
so for example, my initial array of malaria-positive images has a shape of (13780, 150, 150)
next step - clean up the jupyter notebook and apply this change to the Train_Test_split I have already done previously.
Note: my np.reshape took the each image to an array of (150, 150) down from its original (164, 112, 3). Time permitting, reshape back 
noticed that the data is between 0 and 1, but not normalized/scaled to 0 to 1. will use TensorFlow with Keras to adjust for this.
takeaways from the day - look into Layers other than Dense, how about Convolutional and Map-Pooling Layers? 



### Technologies Used
pandas
numpy
Google's TensorFlow 
Keras
